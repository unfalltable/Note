---
title: 中间件
categories: 面试
tags: [中间件,面试]
---

## WEB

- [ ] 简述一下伪共享的概念以及如何避免
  - [ ] 是什么
  - [x] 怎么解决
    - @Contended，除了需要的内容之外用无意义的数据填充缓存行
- [ ] okhttp如何处理网络缓存的
- [ ] epoll和poll的区别
- [ ] BIO/NIO/IO多路复用
  - [ ] BIO有什么缺陷
  - [ ] 针对C10K这样的需求，NIO靠什么解决
    - NIO的选择器selector可以做到一个线程监听多个socket
  - [ ] 多路复用操作系统函数select()的工作原理
    - 准备需要监听的socket集合，用一个rset保存socketId

    - 调用select函数会涉及到用户态和内核态的切换

    - 还需要复制rset集合到内核态

    - 循环监听rset中记录的socket，有就绪的就将其对应的rset位置位

    - 然后把内核态的rset复制到用户态中去
  - [ ] select()默认监听socket的数量为什么是1024
  - [ ] select()第一遍O(n)未发现就绪的socket，如果后续某一个socket就绪后。select是如何感知的？是不停的轮询吗
    - 第一遍未发现就绪的socket后，会将当前线程保留到每个需要监听的socket的等待队列中

    - 然后当前线程从工作队列中移除

    - 这时客户端向服务端发送了数据，数据通过网线到网卡，网卡的DMA将数据写进内存，数据传输结束后会触发网络传输完毕中断程序，cpu会将当前正在运行的线程挂起然后执行这个中断程序的逻辑

    - 根据内存中的数据包分析出是哪个socket的数据，而且tcp/ip协议传输的数据包是有端口号的，这样就能找到对应的socket实例

    - 然后数据导入到socket的读缓冲区，然后会检查socket的等待队列，有等待的队列就将其加入cpu工作队列

    - 然后select函数又会执行了，就能发现就绪的socket了
  - [ ] poll()和select()主要区别是什么
    - 参数不一样

    - select用的是bitmap，长度是1024

    - poll使用的数组，长度很大
      - 数组中的结构是pollfd，里面是fd、events、revents
  - [ ] 为什么会有epoll这个技术，产生的背景是
    - 为了解决select和poll的缺陷
      - 用户态和内核态频繁切换
      - 不能反映是哪个socket就绪了，每次需要遍历判断
  - [ ] epoll的工作原理是
    - epoll_create 在内核态创建一个eventpoll对象
  - [ ] eventpoll对象的就绪列表数据是如何维护的呢
    - 需要先描述一遍将socket加入epoll对象监听列表的过程
    - 当有socket进入就绪队列后，会检查epoll对象的等待队列

    - 如果等待队列中有进程，则将其加入cpu工作队列
  - [ ] epoll怎么得知哪些socket是就绪的
    - epoll_wait中会传入一个epoll_events 并将其置为1，然后拷贝到数组指针中，然后将这个数组返回给用户空间
  - [ ] epoll_wait可以设置为非阻塞吗
    - 默认是阻塞的
    - 调用时可以传入参数来设置
      - 设置为0就是非阻塞的
  - [ ] eventpoll对象中存放需要检查的socket信息是采用的什么数据结构？为什么
    - 红黑树，因为经常有增删改，稳定的O(logN)
  - [ ] epoll往监听事件列表中添加一个新事件过程
    - 内核程序会把当前eventpoll对象追加到socket的等待队列中
    - socket接收完客户端发送的数据后触发中断程序

    - 根据内存中的数据找到对应的socket的读缓冲区，发现等待队列中的是一个eventpoll对象引用

    - 然后会将当前socket的引用加入到epoll对象的监听列表末尾


## MQ

|          | RabbitMQ                               | RocketMQ                         | Kafka                        |
| -------- | -------------------------------------- | -------------------------------- | ---------------------------- |
| 优点     | 消息可靠性高，功能全面，性能好，高并发 | 高吞吐、高性能、高可用、功能齐全 | 吞吐量大，性能好，集群高可用 |
| 缺点     | 消息堆积影响性能，erlang不好定制       | 生态不成熟、只支持Java           | 数据丢失，功能单一           |
| 吞吐量   | 万级                                   | 十万级                           | 百万级                       |
| 速度     | 微秒级                                 | 毫秒级                           | 毫秒级                       |
| 使用场景 | 大部分场景                             | 全场景                           | 日志分析，大数据采集         |

- [ ] 为什么使用消息队列

  - 解耦：
    - 数据需要多方使用时，如果直接调用对应的服务，耦合度较高，而且扩展/剔除不方便，还要确认消息是否重发，是否持久化
    - 有MQ时，数据发送方只需要将数据发送到mq中，哪个服务需要就去mq中取即可
    - 通过mq就将数据发送方跟其他系统解耦了
  - 异步
    - 提高系统的响应速度和吞吐量，不用等到结果就可以提前响应
  - 削峰
    - 以稳定的系统资源应对突发的流量冲击

- [ ] 使用消息队列的缺点

  - 系统可用性降低，MQ宕机，整个业务都会影响
  - 系统的复杂度提高
  - 一致性问题

- [ ] 如何保证消息队列的高可用

  - RabbitMQ 

    - 镜像集群模式

  - Kafka
    - 副本机制

- [ ] 如何设计一个MQ

  - 首先需要设计一个先进先出FIFO的数据结构，高效，可扩展
  - 扩展为分布式队列，分布式集群管理
  - 基于Topic定制消息路由策略，发送者路由策略，消费者与对列的对应关系，消费者路由策略
  - 实现高效的网络通信，Http
  - 规划日志文件，实现文件高效读写，零拷贝，顺序写（性能高），服务重启快速恢复
  - 死信队列，延迟队列、事务消息

- [ ] 如何保证消息可靠传输

  1. 保证消息不能重复
     - 消费者端实现幂等性
     - 每个消息带一个有业务标识的ID，来进行幂等判断，或者使用全局唯一ID
     - RocketMQ可以给每个消息分配了一个MessaheID，但是不太好
  2. 保证消息不能丢失
     - 主从间信息同步时
       - 同步同步、两阶段提交（RocketMQ）
       - 镜像集群（RabbitMQ）

     - 生产者发送消息给MQ时
       - 消息发送+回调（kafka、RocketMQ、RabbitMQ）
       - 事务消息机制（RocketMQ）
         - 会先发送一个half消息测试MQ是否有问题
           - Commit：推送实际消息
           - RollBack：丢弃该消息
           - UnKnow：回查，默认15次
       - 手动事务机制、Publisher Comfirm（类似RocketMQ事务消息机制）（RabbitMQ）
         - 事务属于同步机制，对性能影响较大
         - Comfirm属于异步机制，性能较好（一般使用这个）
           - 有同步、批量、异步等模式

     - 消费者获取MQ消息时
       - 得先关闭MQ的自动ACK确认（RabbitMQ）
       - 保证消费者真正消费之后才删除消息，消费端ACK
       - 不采用异步消费即可

     - MQ自身接受消息时
       - 保证确实收到并持久化消息，再进行ACK确认	
       - MQ宕机重新选举时可能会丢数据（Kafka）
       - 同步刷盘（RocketMQ）
       - 持久化队列、Quorum（RabbitMQ）

- [ ] 如何保证消息的顺序消费

  - 乱序的原因

    - 消费者端没有顺序的进行消息的消费（RabbitMQ）
    - 消费者多线程的消费消息（Kafka）
    - 一个topic中有多个队列，消息会因为负载均衡保存在不同的队列中

  - 解决方法

    - 生产者

      - 保证一类消息都放在一个队列上

      - 在Producer发消息时注入一个**消息队列选择器（MessageQueueSelector）**对象

    - 消费者

      - 消费者一次消费整个队列中的消息

      - Consumer需要注册消息监听，传入MessageQueueOrderly对象

      ```java
        consumer.registerMessageListener(new MessageQueueOrderly(){
            @Overide
            public ConsumerOrderlyStatus comsumeMessage(List<MessageExt> msgs, ConsumerOrderlyContext context){
                
            }
        });
      ```


  - RabbitMq

    - 要保证目标exchange只对应一个队列，并且一个队列只对应一个消费者
    - 消费者不直接消费消息，取消息存进一个队列中，再消费

  - Kafka

    - 生产者通过定制partition分配规则，将相同key的消息分配到同一个partition

- [ ] 如何解决消息积压

  - 熔断隔离、灰度发布、优化线程池配置、消息转发
  - 临时紧急扩容，具体操作步骤和思路如下：

    - 先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。
    - 新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 队列 数量。
    - 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的队列中。
    - 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。
    - 等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的 consumer 机器来消费消息

  RocketMQ

  - 提高消费并行度
  - 批量消费消息
  - 跳过非重要的消息
  - 优化消息消费的过程

- [ ] MQ消息过期失效

  RabbitMQ

  - 可以设置过期时间，如果此时出现消息积压就会丢失大量消息

  - 过期失效的消息只能批量重导了

## Mybatis / MybatisPlus

- [ ] if标签中的test
  - [ ] 进行判断时，== 两边的数据类型不同可以判断吗
    - 可以判断，底层是使用的OGNL表达式来解析的，可以支持不同数据类型之间的比较

  - [ ] test后接单引号和双引号的区别

- [ ] {}和${}的区别
  - ${}是properties文件种的变量占位符，可以用于标签属性值和sql内部，属于静态文本替换
  - {}是sql的参数占位符，mybatis会将sql中的#{}替换为？，在sql执行时会用PreparedStatement的set方法来赋值
  - 序给sql中的？设置参数值，可以有效的防止sql注入
